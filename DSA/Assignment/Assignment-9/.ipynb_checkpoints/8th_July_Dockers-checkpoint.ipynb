{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfc5597",
   "metadata": {},
   "source": [
    "# Assignment 9 - (Dockers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d2414f",
   "metadata": {},
   "source": [
    "## TOPIC: Docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151045c",
   "metadata": {},
   "source": [
    "1. Scenario: You are building a microservices-based application using Docker. Design a Docker Compose file that sets up three containers: a web server container, a database container, and a cache container. Ensure that the containers can communicate with each other properly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b70c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "version: '3'\n",
    "services:\n",
    "  webserver:\n",
    "    build:\n",
    "      context: .\n",
    "      dockerfile: Dockerfile\n",
    "    ports:\n",
    "      - 80:80\n",
    "    depends_on:\n",
    "      - database\n",
    "      - cache\n",
    "\n",
    "  database:\n",
    "    image: postgres:latest\n",
    "    environment:\n",
    "      - POSTGRES_USER=myuser\n",
    "      - POSTGRES_PASSWORD=mypassword\n",
    "      - POSTGRES_DB=mydatabase\n",
    "\n",
    "  cache:\n",
    "    image: redis:latest\n",
    "\n",
    "\n",
    "            \n",
    "#run the following command to start the containers\n",
    "#docker-compose up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345c81ec",
   "metadata": {},
   "source": [
    "2. Scenario: You want to scale your Docker containers dynamically based on the incoming traffic. Write a Python script that utilizes Docker SDK to monitor the CPU usage of a container and automatically scales the number of replicas based on a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf45b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "import psutil\n",
    "import time\n",
    "\n",
    "# Define the Docker API client\n",
    "client = docker.from_env()\n",
    "\n",
    "# Define the container information\n",
    "container_name = \"my_container\"\n",
    "threshold = 70  # CPU usage threshold for scaling (in percentage)\n",
    "\n",
    "# Monitor and scale the container\n",
    "while True:\n",
    "    # Get the CPU usage of the container\n",
    "    container = client.containers.get(container_name)\n",
    "    container_stats = container.stats(stream=False)\n",
    "    cpu_percent = container_stats[\"cpu_stats\"][\"cpu_usage\"][\"total_usage\"] / container_stats[\"cpu_stats\"][\"system_cpu_usage\"] * 100\n",
    "\n",
    "    # Scale the container based on CPU usage\n",
    "    if cpu_percent > threshold:\n",
    "        # Scale up the container\n",
    "        client.containers.run(\n",
    "            image=container.image,\n",
    "            detach=True\n",
    "        )\n",
    "        print(\"Scaled up container due to high CPU usage:\", container_name)\n",
    "\n",
    "    time.sleep(10)  # Adjust the sleep duration as needed\n",
    "\n",
    "#run the following command  before running the script.   \n",
    "#pip install docker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05bfed6",
   "metadata": {},
   "source": [
    "3. Scenario: You have a Docker image stored on a private registry. Develop a script in Bash that authenticates with the registry, pulls the latest version of the image, and runs a container based on that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f948e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Registry authentication credentials\n",
    "registry_url=\"your-registry-url\"\n",
    "username=\"your-username\"\n",
    "password=\"your-password\"\n",
    "\n",
    "# Image details\n",
    "image_name=\"your-image-name\"\n",
    "container_name=\"your-container-name\"\n",
    "\n",
    "# Authenticate with the private registry\n",
    "docker login -u \"$username\" -p \"$password\" \"$registry_url\"\n",
    "\n",
    "# Pull the latest version of the image\n",
    "docker pull \"$registry_url/$image_name\"\n",
    "\n",
    "# Run a container based on the latest image\n",
    "docker run -d --name \"$container_name\" \"$registry_url/$image_name\"\n",
    "\n",
    "\n",
    "#You can save the script in a file, e.g., pull_and_run.sh, and execute it using bash pull_and_run.sh.\n",
    "#'docker run' command to run a container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041cfaad",
   "metadata": {},
   "source": [
    "## TOPIC: Airflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a2f33b",
   "metadata": {},
   "source": [
    "1. Scenario: You have a data pipeline that requires executing a shell command as part of a task. Create an Airflow DAG that includes a BashOperator to execute a specific shell command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2101d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.bash import BashOperator\n",
    "\n",
    "# Define the DAG\n",
    "dag = DAG(\n",
    "    dag_id='execute_shell_command',\n",
    "    start_date=datetime(2023, 7, 1),\n",
    "    schedule_interval='0 0 * * *',  # Run once daily at midnight\n",
    ")\n",
    "\n",
    "# Define the BashOperator task\n",
    "execute_shell_command = BashOperator(\n",
    "    task_id='execute_shell_command_task',\n",
    "    bash_command='your_shell_command_here',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Set task dependencies\n",
    "execute_shell_command  # No dependencies\n",
    "\n",
    "#Save the script as a Python file, e.g., execute_shell_command_dag.py, and place it in your Airflow DAG\n",
    "#directory. Airflow will automatically detect the DAG and make it available for scheduling and execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0bd053",
   "metadata": {},
   "source": [
    "2. Scenario: You want to create dynamic tasks in Airflow based on a list of inputs. Design an Airflow DAG that generates tasks dynamically using PythonOperator, where each task processes an element from the input list.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5887c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "\n",
    "# Define the function to be executed by each task\n",
    "def process_input(input_value):\n",
    "    # Perform processing logic for each input value\n",
    "    print(f\"Processing input: {input_value}\")\n",
    "\n",
    "# Define the input list\n",
    "input_list = ['Input A', 'Input B', 'Input C']  # Modify with your actual input values\n",
    "\n",
    "# Define the DAG\n",
    "dag = DAG(\n",
    "    dag_id='dynamic_task_generation',\n",
    "    start_date=datetime(2023, 7, 1),\n",
    "    schedule_interval=None,  # Set to None to disable automatic scheduling\n",
    ")\n",
    "\n",
    "# Generate dynamic tasks using PythonOperator\n",
    "for input_value in input_list:\n",
    "    task_id = f'task_{input_value}'\n",
    "    task = PythonOperator(\n",
    "        task_id=task_id,\n",
    "        python_callable=process_input,\n",
    "        op_kwargs={'input_value': input_value},\n",
    "        dag=dag,\n",
    "    )\n",
    "\n",
    "    # Set task dependencies\n",
    "    task  # No dependencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69862497",
   "metadata": {},
   "source": [
    "3. Scenario: You need to set up a complex task dependency in Airflow, where Task B should start only if Task A has successfully completed. Implement this dependency using the \"TriggerDagRunOperator\" in Airflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af710f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from airflow import DAG\n",
    "from airflow.operators.dagrun import TriggerDagRunOperator\n",
    "from airflow.operators.dummy import DummyOperator\n",
    "\n",
    "# Define the DAG\n",
    "dag = DAG(\n",
    "    dag_id='complex_task_dependency',\n",
    "    start_date=datetime(2023, 7, 1),\n",
    "    schedule_interval=None,  # Set to None to disable automatic scheduling\n",
    ")\n",
    "\n",
    "# Define Task A\n",
    "task_a = DummyOperator(\n",
    "    task_id='task_a',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Define Task B\n",
    "task_b = DummyOperator(\n",
    "    task_id='task_b',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Define the TriggerDagRunOperator to trigger Task B after Task A\n",
    "trigger_task_b = TriggerDagRunOperator(\n",
    "    task_id='trigger_task_b',\n",
    "    trigger_dag_id='complex_task_dependency',\n",
    "    dag=dag,\n",
    ")\n",
    "\n",
    "# Set task dependencies\n",
    "task_a >> trigger_task_b >> task_b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b63456",
   "metadata": {},
   "source": [
    "## TOPIC: Sqoop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2034e9f4",
   "metadata": {},
   "source": [
    "1. Scenario: You want to import data from an Oracle database into Hadoop using Sqoop, but you only need to import specific columns from a specific table. Write a Sqoop command that performs the import, including the necessary arguments for column selection and table mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9727432",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop import \\\n",
    "--connect jdbc:oracle:thin:@<hostname>:<port>/<database> \\\n",
    "--username <username> \\\n",
    "--password <password> \\\n",
    "--table <table_name> \\\n",
    "--columns \"<column1>,<column2>,<column3>\" \\\n",
    "--target-dir <target_directory> \\\n",
    "--as-parquetfile \\\n",
    "--num-mappers 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c08bd1",
   "metadata": {},
   "source": [
    "2. Scenario: You have a requirement to perform an incremental import of data from a MySQL database into Hadoop using Sqoop. Design a Sqoop command that imports only the new or updated records since the last import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2179cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop import \\\n",
    "--connect jdbc:mysql://<hostname>:<port>/<database> \\\n",
    "--username <username> \\\n",
    "--password <password> \\\n",
    "--table <table_name> \\\n",
    "--target-dir <target_directory> \\\n",
    "--as-parquetfile \\\n",
    "--incremental append \\\n",
    "--check-column <check_column> \\\n",
    "--last-value <last_import_value> \\\n",
    "--num-mappers 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aeae54",
   "metadata": {},
   "source": [
    "3. Scenario: You need to export data from Hadoop to a Microsoft SQL Server database using Sqoop. Develop a Sqoop command that exports the data, considering factors like database connection details, table mapping, and appropriate data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7cd855",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop export \\\n",
    "--connect \"jdbc:sqlserver://<hostname>:<port>;database=<database>\" \\\n",
    "--username <username> \\\n",
    "--password <password> \\\n",
    "--table <table_name> \\\n",
    "--export-dir <export_directory> \\\n",
    "--input-fields-terminated-by '\\t' \\\n",
    "--input-lines-terminated-by '\\n' \\\n",
    "--num-mappers 4\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
